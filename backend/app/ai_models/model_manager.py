"""
AIæ¨¡å‹ç®¡ç†å™¨ - ä¸‰å±‚æ€ç»´å»ºæ¨¡æ¶æ„
"""

import os
import asyncio
import torch
import numpy as np
from typing import Dict, List, Any, Optional, Union
from pathlib import Path

from transformers import (
    AutoTokenizer, AutoModel, AutoModelForCausalLM,
    CLIPProcessor, CLIPModel,
    AutoModelForSequenceClassification,
    pipeline
)
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.cluster import KMeans
from sklearn.metrics.pairwise import cosine_similarity
import cv2
from PIL import Image
from loguru import logger

from ..core.config import settings


class VisualThinkingModel:
    """å½¢è±¡æ€ç»´æ¨¡å‹ - è§†è§‰-è¯­è¨€ç†è§£"""
    
    def __init__(self):
        self.model = None
        self.processor = None
        self.device = "cuda" if torch.cuda.is_available() and settings.ENABLE_GPU else "cpu"
        
    async def initialize(self):
        """åˆå§‹åŒ–æ¨¡å‹"""
        try:
            logger.info("ğŸ”„ æ­£åœ¨åŠ è½½å½¢è±¡æ€ç»´æ¨¡å‹...")
            
            # åŠ è½½CLIPæ¨¡å‹ç”¨äºè§†è§‰-è¯­è¨€ç†è§£
            model_name = "openai/clip-vit-base-patch32"
            self.processor = CLIPProcessor.from_pretrained(
                model_name,
                cache_dir=settings.HUGGINGFACE_CACHE_DIR
            )
            self.model = CLIPModel.from_pretrained(
                model_name,
                cache_dir=settings.HUGGINGFACE_CACHE_DIR
            ).to(self.device)
            
            logger.info("âœ… å½¢è±¡æ€ç»´æ¨¡å‹åŠ è½½å®Œæˆ")
            
        except Exception as e:
            logger.error(f"âŒ å½¢è±¡æ€ç»´æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            raise
    
    async def analyze_image(self, image_data: Union[str, bytes, Image.Image]) -> Dict[str, Any]:
        """åˆ†æå›¾åƒå†…å®¹"""
        try:
            # å¤„ç†è¾“å…¥å›¾åƒ
            if isinstance(image_data, str):
                image = Image.open(image_data)
            elif isinstance(image_data, bytes):
                image = Image.open(io.BytesIO(image_data))
            else:
                image = image_data
            
            # é¢„å®šä¹‰çš„æ€ç»´æ¦‚å¿µ
            concepts = [
                "åˆ›æ–°æ€ç»´", "é€»è¾‘æ¨ç†", "æŠ½è±¡æ¦‚å¿µ", "å…·ä½“å®ç‰©",
                "æƒ…æ„Ÿè¡¨è¾¾", "ç©ºé—´å…³ç³»", "æ—¶é—´æ¦‚å¿µ", "å› æœå…³ç³»",
                "ç§‘å­¦åŸç†", "è‰ºæœ¯ç¾æ„Ÿ", "ç¤¾ä¼šäº’åŠ¨", "é—®é¢˜è§£å†³"
            ]
            
            # ä½¿ç”¨CLIPè¿›è¡Œå›¾åƒ-æ–‡æœ¬åŒ¹é…
            inputs = self.processor(
                text=concepts,
                images=image,
                return_tensors="pt",
                padding=True
            ).to(self.device)
            
            with torch.no_grad():
                outputs = self.model(**inputs)
                logits_per_image = outputs.logits_per_image
                probs = logits_per_image.softmax(dim=1)
            
            # åˆ†æç»“æœ
            concept_scores = {}
            for i, concept in enumerate(concepts):
                concept_scores[concept] = float(probs[0][i])
            
            # æ‰¾å‡ºä¸»è¦æ¦‚å¿µ
            dominant_concept = max(concept_scores, key=concept_scores.get)
            confidence = concept_scores[dominant_concept]
            
            return {
                "analysis_type": "visual_thinking",
                "dominant_concept": dominant_concept,
                "confidence": confidence,
                "concept_scores": concept_scores,
                "thinking_style": "å½¢è±¡æ€ç»´" if confidence > 0.3 else "æ··åˆæ€ç»´"
            }
            
        except Exception as e:
            logger.error(f"å›¾åƒåˆ†æå¤±è´¥: {e}")
            return {"error": str(e)}
    
    async def extract_visual_features(self, image_data: Union[str, bytes, Image.Image]) -> np.ndarray:
        """æå–è§†è§‰ç‰¹å¾å‘é‡"""
        try:
            if isinstance(image_data, str):
                image = Image.open(image_data)
            elif isinstance(image_data, bytes):
                image = Image.open(io.BytesIO(image_data))
            else:
                image = image_data
                
            inputs = self.processor(images=image, return_tensors="pt").to(self.device)
            
            with torch.no_grad():
                image_features = self.model.get_image_features(**inputs)
                return image_features.cpu().numpy().flatten()
                
        except Exception as e:
            logger.error(f"è§†è§‰ç‰¹å¾æå–å¤±è´¥: {e}")
            return np.array([])


class LogicalThinkingModel:
    """é€»è¾‘æ€ç»´æ¨¡å‹ - æ¨ç†å’Œåˆ†æ"""
    
    def __init__(self):
        self.model = None
        self.tokenizer = None
        self.classifier = None
        self.device = "cuda" if torch.cuda.is_available() and settings.ENABLE_GPU else "cpu"
        
    async def initialize(self):
        """åˆå§‹åŒ–æ¨¡å‹"""
        try:
            logger.info("ğŸ”„ æ­£åœ¨åŠ è½½é€»è¾‘æ€ç»´æ¨¡å‹...")
            
            # åŠ è½½RoBERTaæ¨¡å‹ç”¨äºæ–‡æœ¬ç†è§£
            model_name = "roberta-base"
            self.tokenizer = AutoTokenizer.from_pretrained(
                model_name,
                cache_dir=settings.HUGGINGFACE_CACHE_DIR
            )
            self.model = AutoModel.from_pretrained(
                model_name,
                cache_dir=settings.HUGGINGFACE_CACHE_DIR
            ).to(self.device)
            
            # åˆå§‹åŒ–åˆ†ç±»å™¨ç”¨äºé€»è¾‘æ¨ç†
            self.classifier = pipeline(
                "text-classification",
                model="microsoft/DialoGPT-medium",
                device=0 if self.device == "cuda" else -1
            )
            
            logger.info("âœ… é€»è¾‘æ€ç»´æ¨¡å‹åŠ è½½å®Œæˆ")
            
        except Exception as e:
            logger.error(f"âŒ é€»è¾‘æ€ç»´æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            raise
    
    async def analyze_reasoning(self, text: str) -> Dict[str, Any]:
        """åˆ†ææ–‡æœ¬çš„é€»è¾‘æ¨ç†ç»“æ„"""
        try:
            # ç¼–ç æ–‡æœ¬
            inputs = self.tokenizer(
                text,
                return_tensors="pt",
                padding=True,
                truncation=True,
                max_length=512
            ).to(self.device)
            
            with torch.no_grad():
                outputs = self.model(**inputs)
                embeddings = outputs.last_hidden_state.mean(dim=1)
            
            # åˆ†æé€»è¾‘æ¨¡å¼
            logical_patterns = self._detect_logical_patterns(text)
            reasoning_strength = self._calculate_reasoning_strength(text)
            
            return {
                "analysis_type": "logical_thinking",
                "logical_patterns": logical_patterns,
                "reasoning_strength": reasoning_strength,
                "coherence_score": self._calculate_coherence(text),
                "argument_structure": self._analyze_argument_structure(text),
                "thinking_style": "é€»è¾‘æ€ç»´"
            }
            
        except Exception as e:
            logger.error(f"é€»è¾‘æ¨ç†åˆ†æå¤±è´¥: {e}")
            return {"error": str(e)}
    
    def _detect_logical_patterns(self, text: str) -> List[str]:
        """æ£€æµ‹é€»è¾‘æ¨¡å¼"""
        patterns = []
        
        # å› æœå…³ç³»
        if any(word in text for word in ["å› ä¸º", "æ‰€ä»¥", "å¯¼è‡´", "å› æ­¤", "ç”±äº"]):
            patterns.append("å› æœæ¨ç†")
        
        # å½’çº³æ¨ç†
        if any(word in text for word in ["ä¾‹å¦‚", "æ¯”å¦‚", "ä¸€èˆ¬æ¥è¯´", "é€šå¸¸"]):
            patterns.append("å½’çº³æ¨ç†")
        
        # æ¼”ç»æ¨ç†
        if any(word in text for word in ["å¦‚æœ", "é‚£ä¹ˆ", "å‡è®¾", "å‰æ"]):
            patterns.append("æ¼”ç»æ¨ç†")
        
        # å¯¹æ¯”åˆ†æ
        if any(word in text for word in ["ç›¸æ¯”", "å¯¹æ¯”", "ç„¶è€Œ", "ä½†æ˜¯", "ç›¸å"]):
            patterns.append("å¯¹æ¯”åˆ†æ")
        
        return patterns
    
    def _calculate_reasoning_strength(self, text: str) -> float:
        """è®¡ç®—æ¨ç†å¼ºåº¦"""
        reasoning_words = [
            "åˆ†æ", "æ¨ç†", "è¯æ˜", "è®ºè¯", "ç»“è®º", "å‡è®¾",
            "éªŒè¯", "é€»è¾‘", "åŸç†", "è§„å¾‹", "å› æœ", "å…³è”"
        ]
        
        word_count = len(text.split())
        reasoning_count = sum(1 for word in reasoning_words if word in text)
        
        return min(reasoning_count / max(word_count * 0.1, 1), 1.0)
    
    def _calculate_coherence(self, text: str) -> float:
        """è®¡ç®—æ–‡æœ¬è¿è´¯æ€§"""
        sentences = text.split('ã€‚')
        if len(sentences) < 2:
            return 1.0
        
        # ç®€å•çš„è¿è´¯æ€§è¯„åˆ†ï¼ˆåŸºäºè¿æ¥è¯ï¼‰
        connection_words = ["å› æ­¤", "æ‰€ä»¥", "ç„¶è€Œ", "ä½†æ˜¯", "è€Œä¸”", "å¦å¤–", "æ­¤å¤–"]
        connections = sum(1 for word in connection_words if word in text)
        
        return min(connections / len(sentences), 1.0)
    
    def _analyze_argument_structure(self, text: str) -> Dict[str, Any]:
        """åˆ†æè®ºè¯ç»“æ„"""
        return {
            "has_premise": any(word in text for word in ["å‰æ", "å‡è®¾", "åŸºäº"]),
            "has_evidence": any(word in text for word in ["è¯æ®", "æ•°æ®", "äº‹å®", "ç ”ç©¶"]),
            "has_conclusion": any(word in text for word in ["ç»“è®º", "æ€»ç»“", "å› æ­¤", "æ‰€ä»¥"]),
            "argument_type": "æ¼”ç»è®ºè¯" if "å¦‚æœ" in text and "é‚£ä¹ˆ" in text else "å½’çº³è®ºè¯"
        }


class CreativeThinkingModel:
    """åˆ›é€ æ€ç»´æ¨¡å‹ - ç”Ÿæˆå’Œåˆ›æ–°"""
    
    def __init__(self):
        self.model = None
        self.tokenizer = None
        self.device = "cuda" if torch.cuda.is_available() and settings.ENABLE_GPU else "cpu"
        
    async def initialize(self):
        """åˆå§‹åŒ–æ¨¡å‹"""
        try:
            logger.info("ğŸ”„ æ­£åœ¨åŠ è½½åˆ›é€ æ€ç»´æ¨¡å‹...")
            
            # åŠ è½½GPT-2æ¨¡å‹ç”¨äºåˆ›æ„ç”Ÿæˆ
            model_name = "gpt2-medium"
            self.tokenizer = AutoTokenizer.from_pretrained(
                model_name,
                cache_dir=settings.HUGGINGFACE_CACHE_DIR
            )
            self.model = AutoModelForCausalLM.from_pretrained(
                model_name,
                cache_dir=settings.HUGGINGFACE_CACHE_DIR
            ).to(self.device)
            
            # è®¾ç½®pad_token
            if self.tokenizer.pad_token is None:
                self.tokenizer.pad_token = self.tokenizer.eos_token
            
            logger.info("âœ… åˆ›é€ æ€ç»´æ¨¡å‹åŠ è½½å®Œæˆ")
            
        except Exception as e:
            logger.error(f"âŒ åˆ›é€ æ€ç»´æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            raise
    
    async def generate_creative_ideas(
        self, 
        prompt: str, 
        num_ideas: int = 3,
        max_length: int = 100
    ) -> Dict[str, Any]:
        """ç”Ÿæˆåˆ›æ„æƒ³æ³•"""
        try:
            inputs = self.tokenizer.encode(
                prompt,
                return_tensors="pt",
                padding=True,
                truncation=True
            ).to(self.device)
            
            ideas = []
            for i in range(num_ideas):
                with torch.no_grad():
                    outputs = self.model.generate(
                        inputs,
                        max_length=max_length,
                        num_return_sequences=1,
                        temperature=0.8 + i * 0.1,  # ä¸åŒçš„æ¸©åº¦äº§ç”Ÿä¸åŒçš„åˆ›æ„
                        do_sample=True,
                        top_k=50,
                        top_p=0.95,
                        pad_token_id=self.tokenizer.eos_token_id
                    )
                
                generated_text = self.tokenizer.decode(
                    outputs[0], 
                    skip_special_tokens=True
                )
                
                # ç§»é™¤åŸå§‹æç¤º
                new_idea = generated_text[len(prompt):].strip()
                if new_idea:
                    ideas.append({
                        "idea": new_idea,
                        "creativity_score": self._calculate_creativity_score(new_idea),
                        "novelty": self._assess_novelty(new_idea, prompt)
                    })
            
            return {
                "analysis_type": "creative_thinking",
                "generated_ideas": ideas,
                "creativity_level": np.mean([idea["creativity_score"] for idea in ideas]),
                "thinking_style": "åˆ›é€ æ€ç»´"
            }
            
        except Exception as e:
            logger.error(f"åˆ›æ„ç”Ÿæˆå¤±è´¥: {e}")
            return {"error": str(e)}
    
    def _calculate_creativity_score(self, text: str) -> float:
        """è®¡ç®—åˆ›æ„åˆ†æ•°"""
        creative_words = [
            "åˆ›æ–°", "ç‹¬ç‰¹", "æ–°é¢–", "åŸåˆ›", "çªç ´", "æƒ³è±¡",
            "çµæ„Ÿ", "åˆ›æ„", "å‘æ˜", "è®¾è®¡", "è‰ºæœ¯", "ç¾æ„Ÿ"
        ]
        
        word_count = len(text.split())
        creative_count = sum(1 for word in creative_words if word in text)
        
        # åŸºäºåˆ›æ„è¯æ±‡å¯†åº¦å’Œæ–‡æœ¬é•¿åº¦
        density_score = creative_count / max(word_count * 0.1, 1)
        length_bonus = min(word_count / 50, 1.0)  # æ›´é•¿çš„æ–‡æœ¬å¯èƒ½æ›´æœ‰åˆ›æ„
        
        return min(density_score + length_bonus, 1.0)
    
    def _assess_novelty(self, idea: str, prompt: str) -> float:
        """è¯„ä¼°æ–°é¢–æ€§"""
        # ç®€å•çš„æ–°é¢–æ€§è¯„ä¼°ï¼šä¸æç¤ºçš„ç›¸ä¼¼åº¦è¶Šä½ï¼Œæ–°é¢–æ€§è¶Šé«˜
        try:
            vectorizer = TfidfVectorizer()
            vectors = vectorizer.fit_transform([prompt, idea])
            similarity = cosine_similarity(vectors[0:1], vectors[1:2])[0][0]
            return 1.0 - similarity
        except:
            return 0.5


class ModelManager:
    """AIæ¨¡å‹ç»Ÿä¸€ç®¡ç†å™¨"""
    
    def __init__(self):
        self.visual_model = VisualThinkingModel()
        self.logical_model = LogicalThinkingModel()
        self.creative_model = CreativeThinkingModel()
        self.initialized = False
        
    async def initialize(self):
        """åˆå§‹åŒ–æ‰€æœ‰AIæ¨¡å‹"""
        try:
            logger.info("ğŸš€ å¼€å§‹åˆå§‹åŒ–AIæ¨¡å‹ç®¡ç†å™¨...")
            
            # å¹¶è¡Œåˆå§‹åŒ–æ¨¡å‹
            await asyncio.gather(
                self.visual_model.initialize(),
                self.logical_model.initialize(),
                self.creative_model.initialize()
            )
            
            self.initialized = True
            logger.info("ğŸ‰ AIæ¨¡å‹ç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆï¼")
            
        except Exception as e:
            logger.error(f"âŒ AIæ¨¡å‹ç®¡ç†å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
            raise
    
    async def analyze_thinking_pattern(
        self, 
        input_data: Dict[str, Any]
    ) -> Dict[str, Any]:
        """ç»¼åˆåˆ†ææ€ç»´æ¨¡å¼"""
        try:
            if not self.initialized:
                raise Exception("æ¨¡å‹ç®¡ç†å™¨æœªåˆå§‹åŒ–")
            
            results = {}
            
            # æ ¹æ®è¾“å…¥ç±»å‹é€‰æ‹©åˆ†ææ–¹æ³•
            if "text" in input_data:
                # é€»è¾‘æ€ç»´åˆ†æ
                logical_result = await self.logical_model.analyze_reasoning(
                    input_data["text"]
                )
                results["logical_thinking"] = logical_result
                
                # åˆ›é€ æ€ç»´åˆ†æ
                creative_result = await self.creative_model.generate_creative_ideas(
                    input_data["text"]
                )
                results["creative_thinking"] = creative_result
            
            if "image" in input_data:
                # å½¢è±¡æ€ç»´åˆ†æ
                visual_result = await self.visual_model.analyze_image(
                    input_data["image"]
                )
                results["visual_thinking"] = visual_result
            
            # ç»¼åˆåˆ†æ
            thinking_summary = self._synthesize_thinking_analysis(results)
            
            return {
                "individual_analyses": results,
                "thinking_summary": thinking_summary,
                "timestamp": settings.get_current_time()
            }
            
        except Exception as e:
            logger.error(f"æ€ç»´æ¨¡å¼åˆ†æå¤±è´¥: {e}")
            return {"error": str(e)}
    
    def _synthesize_thinking_analysis(self, results: Dict[str, Any]) -> Dict[str, Any]:
        """ç»¼åˆæ€ç»´åˆ†æç»“æœ"""
        thinking_scores = {}
        dominant_style = "å¹³è¡¡æ€ç»´"
        
        # æ”¶é›†å„ç§æ€ç»´çš„å¾—åˆ†
        if "visual_thinking" in results and "confidence" in results["visual_thinking"]:
            thinking_scores["å½¢è±¡æ€ç»´"] = results["visual_thinking"]["confidence"]
        
        if "logical_thinking" in results and "reasoning_strength" in results["logical_thinking"]:
            thinking_scores["é€»è¾‘æ€ç»´"] = results["logical_thinking"]["reasoning_strength"]
        
        if "creative_thinking" in results and "creativity_level" in results["creative_thinking"]:
            thinking_scores["åˆ›é€ æ€ç»´"] = results["creative_thinking"]["creativity_level"]
        
        # ç¡®å®šä¸»å¯¼æ€ç»´é£æ ¼
        if thinking_scores:
            dominant_style = max(thinking_scores, key=thinking_scores.get)
            max_score = thinking_scores[dominant_style]
            
            # å¦‚æœæœ€é«˜åˆ†ä¸å¤Ÿé«˜ï¼Œåˆ™è®¤ä¸ºæ˜¯å¹³è¡¡æ€ç»´
            if max_score < 0.6:
                dominant_style = "å¹³è¡¡æ€ç»´"
        
        return {
            "dominant_thinking_style": dominant_style,
            "thinking_scores": thinking_scores,
            "balance_index": self._calculate_balance_index(thinking_scores),
            "thinking_complexity": len(thinking_scores)
        }
    
    def _calculate_balance_index(self, scores: Dict[str, float]) -> float:
        """è®¡ç®—æ€ç»´å¹³è¡¡æŒ‡æ•°"""
        if not scores:
            return 0.0
        
        values = list(scores.values())
        if len(values) == 1:
            return 0.0
        
        # è®¡ç®—æ ‡å‡†å·®ï¼Œè¶Šå°è¯´æ˜è¶Šå¹³è¡¡
        mean_score = np.mean(values)
        std_score = np.std(values)
        
        # è½¬æ¢ä¸ºå¹³è¡¡æŒ‡æ•°ï¼ˆ0-1ï¼Œ1è¡¨ç¤ºå®Œå…¨å¹³è¡¡ï¼‰
        return max(0, 1 - std_score / max(mean_score, 0.1))
    
    async def cleanup(self):
        """æ¸…ç†èµ„æº"""
        try:
            # æ¸…ç†GPUç¼“å­˜
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
            
            logger.info("âœ… AIæ¨¡å‹èµ„æºæ¸…ç†å®Œæˆ")
            
        except Exception as e:
            logger.error(f"AIæ¨¡å‹èµ„æºæ¸…ç†å¤±è´¥: {e}")
    
    def get_model_status(self) -> Dict[str, Any]:
        """è·å–æ¨¡å‹çŠ¶æ€"""
        return {
            "initialized": self.initialized,
            "device": "cuda" if torch.cuda.is_available() and settings.ENABLE_GPU else "cpu",
            "models": {
                "visual_thinking": self.visual_model.model is not None,
                "logical_thinking": self.logical_model.model is not None,
                "creative_thinking": self.creative_model.model is not None
            },
            "gpu_available": torch.cuda.is_available(),
            "gpu_enabled": settings.ENABLE_GPU
        } 